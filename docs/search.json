[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "If you have to use the same code three times, write a function.\nIf you have to explain the same thing three times, write a blog.\n\nMy name is Ralph-Uwe Börner.\nI teach geophysics at the Technische Universität Bergakademie Freiberg.\nMy research interests are:\n\nTheory of electromagnetic methods in geophysics\nPotential theory and its applications in geophysics\nNumerical simulation of Maxwell’s equations\nFinite Elements\nMATLAB and Julia"
  },
  {
    "objectID": "posts/jupyter/index.html",
    "href": "posts/jupyter/index.html",
    "title": "Jupyter example",
    "section": "",
    "text": "Use Jupyter notebooks as Quarto blog posts\nThis blog post has been entirely written within a Jupyter Notebook.\nYou can use existing Jupyter notebooks as blog entries with just a little modification!\nQuarto can only render Jupyter notebooks properly when you add a YAML header as first cell of your notebook. Just make sure, that this cell is a raw cell.\nFurther, I have renamed the notebook to index.ipynb – though I’m not sure if this is really necessary. This assumption probably fits well with the conventional index.html files sitting in the other blog post folders.\nThe YAML front matter of this notebook looks like this:\n---\ntitle: \"Jupyter example\"\ncategories: [code, jupyter, quarto]\njupyter: \"julia-1.8\"\n---\nThe remaining cells are just plain Jupyter code cells.\n\nusing Plots\ntheme(:vibrant)\n\n\nx = range(0.0, 2π, 101)\n\n0.0:0.06283185307179587:6.283185307179586\n\n\n\nplot(x, sin.(x), label=\"sin(x)\", xlabel=\"x\", ylabel=\"y(x)\")"
  },
  {
    "objectID": "posts/DC_in_the_park/pygimli_inversion.html",
    "href": "posts/DC_in_the_park/pygimli_inversion.html",
    "title": "Geophysical inversion",
    "section": "",
    "text": "The aim of the inversion is to reconstruct the spatial distribution of resistivity in the subsurface. This is based on the measured data, usually ohmic resistances \\(R(L)\\) in \\(\\Omega\\) or apparent resistivities \\(\\rho_s(L)\\) in \\(\\Omega\\cdot m\\). All measured values depend on the location and the geoelectric electrode configuration (denoted here by \\(L\\)).\n\n\nThe pyGIMLi is a Python library. We assume that a Python environment is already installed. The easiest option is anaconda.\nFirst, pyGIMLi must be installed so that it can be accessed under Python. This is done with conda:\nconda install -c gimli -c conda-forge pygimli=1.3.0\n\n\n\nWe import the two libraries pygimli and numpy.\n\n%matplotlib inline\n\n\nimport pygimli as pg\nimport numpy as np\nfrom pygimli.physics import ert\nfrom pygimli.physics.ert import ERTManager\n\n\nprint(pg.__version__)\n\n1.2.6"
  },
  {
    "objectID": "posts/DC_in_the_park/pygimli_inversion.html#inversion-of-a-field-data-set",
    "href": "posts/DC_in_the_park/pygimli_inversion.html#inversion-of-a-field-data-set",
    "title": "Geophysical inversion",
    "section": "Inversion of a field data set",
    "text": "Inversion of a field data set\n\nBackground\nFor this example, we use data from a measurement above the piped stream “Goldbach” in the center of Freiberg.\nThe Goldbach, also known as the Saubach, is an approximately 5 km long left tributary of the Münzbach in Freiberg.\nIts entire course is located in the territory of the city of Freiberg. The headwaters are located between the Großer Teich and the Mittelteich ponds or around these ponds in the Freiberg city forest at an altitude of about 460 meters. After passing the Mittelteich, it flows about 300 m to the northwest and then turns almost 90° to the northeast. Parallel to the Ölmühlenweg it reaches the development boundary of the city of Freiberg. Here, at the level of the Schützenhaus on Chemnitzer Straße, it enters a piped section about 400 m long, which ends at the Mühlteich. After flowing through the Mühlteich, after about 200 m it reaches the Hammerteich with the former Freibergsdorfer Hammerwerk, to which it supplied the service water at that time. After another 800 m it is again piped. After flowing through the Kreuzteiche and the Schlüsselteich, it reaches the Münzbach in the Freiberg district of Loßnitz after about 5 km in a piped condition, having meanwhile turned to a more northerly direction.\n\n\nDC resistivity profile setup\nThe profile measurement was carried out with the Wenner, and Dipole-Dipole configurations using 21 electrodes.\nThe dipole-dipole data set consists of 80 individual measurements, and the Wenner data set consists of 63 individual measurements. All data is stored in the file parkall.mea.\nThe Python object wenner contains all measured data:\n\nwenner = pg.load(\"parkall.mea\")\nprint(wenner)\n\nData: Sensors: 21 data: 143, nonzero entries: ['a', 'b', 'm', 'n', 'rhoa', 'valid']\n\n\n\nwenner['k'] = ert.createGeometricFactors(wenner, numerical=True)\n\nIn the pyGIMLi method ERTManager() all functions for the inversion of geoelectric data (Electrical Resistivity Tomography, ERT) are implemented.\nThe object ertwenner will hold, among others, the model response and the model parameters.\n\nertwenner = ERTManager()\n\nSince our data set does not contain measurement errors, we estimate plausible absolute and relative data errors. Absolute errors are given in \\(\\Omega\\cdot m\\).\n\nwenner['err'] = ertwenner.estimateError(wenner, absoluteError=0.1, relativeError=0.03)\n\nThe following figure shows pseudosections of the apparent resistivity \\(\\rho_s\\). The trapezoidal shape comes from the arbitrary choice of the horizontal reference point in the profile plot for the Wenner or dipole-dipole arrangement. The ordinates in the following two figures represent the electrode spacing for Wenner (WE) and the separation between current pole and voltage dipoles for the dipole-dipole (DD) array. Note: The vertical axis is not a depth axis!\n\nertwenner.showData(wenner, cMap=\"RdBu_r\");\n\n\n\n\n\n\nData inversion\nThe method ert.invert performs the inversion of the data (data) for a specified regularization parameter \\(\\lambda\\) (lam=10) and a maximum model depth of paraDepth=10 meters and a maximum triangular size of the finite elements of paraMaxCellSize=1 \\(m^2\\).\nThe results of the inversion calculation – the distribution of resistivity in the subsurface and the model response – are stored in the object mod.\nThe lam parameter is assigned the value of the selected regularization parameter \\(\\lambda\\).\nIf the value of \\(\\lambda\\) is too low, a singularity of the least squares problem, if present, is expressed by strongly fluctuating values in the resistivity distribution in the subsurface. In the opposite case, if \\(\\lambda\\) is too large, the resistivity distribution becomes very smooth.\nHere we can try out what influence the regularization parameter has on the solution of our problem.\n\nlam = 10\n\n\nmodwenner = ertwenner.invert(wenner, lam=lam, paraMaxCellSize=0.1, paraDepth=6, verbose=False);\n\nThe following figures illustrate the relationship between the model parameters (\\(\\rho(\\mathbf r)\\)) and the measured apparent resistivity (Data) and the model response (Response).\n\nertwenner.showResultAndFit(cMap=\"RdBu_r\");\n\n\n\n\nThe Goldbach flows in a concrete pipe at about profile meter 12.\n\nertwenner.showModel(modwenner, cMap=\"RdBu_r\");\n\n\n\n\nOf interest is the goodness of fit, which we refer to as misfit. This is the relative error between data and model response. A graphical representation of this error is informative:\n\nmisfitwe = ertwenner.inv.response / wenner['rhoa'] * 100 - 100\nme = np.max(np.abs(misfitwe))\npg.show(wenner, misfitwe, cMap=\"RdBu_r\", cMin=-me, cMax=me, label=\"misfit (%)\");\n\n\n\n\nThe global misfit is described with the \\(\\chi^2\\)-statistic and amounts to\n\nertwenner.inv.chi2()\n\n0.8469349648613855"
  },
  {
    "objectID": "posts/DC_in_the_park/pygimli_inversion.html#discussion",
    "href": "posts/DC_in_the_park/pygimli_inversion.html#discussion",
    "title": "Geophysical inversion",
    "section": "Discussion",
    "text": "Discussion\nWe have seen that the inversion result can be influenced by the choice of different parameters. Especially the data fitting and model properties are affected.\n\nWhich parameter controls the roughness of the model?"
  },
  {
    "objectID": "posts/warming_stripes/Warming_Stripes_Makie.html",
    "href": "posts/warming_stripes/Warming_Stripes_Makie.html",
    "title": "Tutorial: How to generate your own warming stripes using Julia",
    "section": "",
    "text": "In this quick tutorial we learn how to create warming stripes similar to those available at showyourstripes.info.\nAlso, this tutorial serves as an opportunity to become familiar with the Julia programming language and some of its packages.\nOur goal is to get as close as possible to the visual appearance of the famous warming stripes.\nWe will use Julia to access and visualize annual air temperature data for Germany provided by the German Meteorological Service The Deutscher Wetterdienst.\nFirst, some packages for data handling, processing and visualization have to be loaded.\nWe will download a large CSV file from the web. To this end, we need the packages CSV and Downloads. Further, we store the data in some kind of a database provided by DataFrames.\nFor the processing of the data we need some statistical quantities from the standard Statistics package.\nThe package RollingFunctions provides tools to smooth temporal data using windowed averages.\nFinally, we create a custom colormap and plot the data with the Makie package.\n\nusing CSV\nusing Downloads\nusing DataFrames\n\nusing Statistics\nusing RollingFunctions\n\nusing ColorSchemes\nusing CairoMakie\n\n\n\nTo get close to the visual style of the warming stripes charts by Ed Hawking, we define a customized colormap.\nThe original color palette from Wikipedia provides the required color codes for the blue-white-red colormap.\n\nwstripesmap = cgrad([\n        \"#08306b\", \"#08519c\", \"#2171b5\", \"#4292c6\", \n        \"#6baed6\", \"#9ecae1\", \"#c6dbef\", \"#deebf7\",\n        \"#ffffff\",\n        \"#fee0d2\", \"#fcbba1\", \"#fc9272\", \"#fb6a4a\",\n        \"#ef3b2c\", \"#cb181d\", \"#a50f15\", \"#67000d\"],\n    categorical=true);\nwstripesmap\n\n\n\n\n\n\n\nWe load data from a URL and store everything in a database structure known as a DataFrame.\n\nurl = \"https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/annual/air_temperature_mean/regional_averages_tm_year.txt\"\nhttp_response = Downloads.download(url)\ndf = CSV.File(http_response, header=2, delim=\";\") |&gt; DataFrame;\n\n\n\n\nAs a baseline we need the average over sufficiently many years. We choose temperature data from the years 1971 to 2000 and calculate the mean temperature.\nFurther, we need the standard deviation of the long-term temperature data from 1901 to 2000.\nA smoothed data set based on a running mean is generated with an averaging window of 30 years length.\n\ndf_baseline = filter(row -&gt; (row.Jahr &gt; 1970) & (row.Jahr &lt; 2001), df)\nwhere = \"Deutschland\"\ncol = df_baseline[!, where];\nmw = mean(col)\n\ndf_longterm = filter(row -&gt; (row.Jahr &gt; 1900) & (row.Jahr &lt; 2001), df)\ncol = df_longterm[!, where];\nsd = std(col)\n\ndata = df[!, where] .- mw;\nm_data = runmean(data, 30);\n\n\n\n\nIn the following code cell, we use Makie to generate a bar chart with annual temperature data relative to the baseline average of 1971 to 2000. The colormap is scaled to +/- 2.6 times the standard deviation of the long-term data from 1901 to 2000 (see How have these graphics been made? in the FAQ at showyourstripes.info).\nWe add as white line the smoothed temperature obtained by calculating running averages with a time window of 30 years length.\nThere is no doubt that the average temperature relative to the baseline data is approaching far more than 1.5 K (or 1.5 °C as it is commonly communicated) for the recent two decades since year 2000.\n\nset_theme!(theme_black())\nfig = Figure(resolution = (1200, 720), fontsize=24, fonts = (; regular= \"sans\"))\nax = Axis(fig[1, 1], \n    title = \"Temperature change in Germany relative to average of 1970-2001\",\n    ylabel = \"K\",\n    xautolimitmargin = (0.02,0.02),\n    yautolimitmargin = (0.02,0.02))\nbarplot!(ax, df.Jahr, data; width=1, gap=0, \n    strokewidth = 0.5, strokecolor = data,\n    color = data, \n    colorrange = (-2.6 * sd, +2.6 * sd),\n    colormap = wstripesmap)\nlines!(ax, df.Jahr, m_data, color=:white)\ntext!(\"Data source: http://opendata.dwd.de\\n\" * \n    \"https://showyourstripes.info by Ed Hawkins, University of Reading, UK\", \n    textsize=10,\n    align=(:left, :center),\n    position = (1880, -1.84))\ntext!(\"The white curve indicates a running average\\n\" *\n    \"with a window length of 30 years.\",\n    textsize = 10,\n    align=(:left, :center),\n    position=(1990, -1.84))\nfig\n\n\n\n\nThe next cell generates the well-known warming stripes for Germany.\n\nset_theme!(theme_minimal())\nfig = Figure(resolution = (780, 120))\nax = Axis(fig[1, 1],\nbackgroundcolor = :transparent,\n        leftspinevisible = false,\n        rightspinevisible = false,\n        bottomspinevisible = false,\n        topspinevisible = false,\n        xticklabelsvisible = false, \n        yticklabelsvisible = false,\n        xgridcolor = :transparent,\n        ygridcolor = :transparent,\n        xminorticksvisible = false,\n        yminorticksvisible = false,\n        xticksvisible = false,\n        yticksvisible = false,\n        xautolimitmargin = (0.0,0.0),\n        yautolimitmargin = (0.0,0.0),)\nhidedecorations!(ax)\nax.titlevisible=false\nhmap = heatmap!(df.Jahr, ones(size(df.Jahr)), data;\n    colorrange = (-2.6 * sd, +2.6 * sd), \n    colormap = wstripesmap)\nfig"
  },
  {
    "objectID": "posts/warming_stripes/Warming_Stripes_Makie.html#data-access",
    "href": "posts/warming_stripes/Warming_Stripes_Makie.html#data-access",
    "title": "Tutorial: How to generate your own warming stripes using Julia",
    "section": "",
    "text": "We load data from a URL and store everything in a database structure known as a DataFrame.\n\nurl = \"https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/annual/air_temperature_mean/regional_averages_tm_year.txt\"\nhttp_response = Downloads.download(url)\ndf = CSV.File(http_response, header=2, delim=\";\") |&gt; DataFrame;"
  },
  {
    "objectID": "posts/warming_stripes/Warming_Stripes_Makie.html#baseline-data-and-long-term-statistics",
    "href": "posts/warming_stripes/Warming_Stripes_Makie.html#baseline-data-and-long-term-statistics",
    "title": "Tutorial: How to generate your own warming stripes using Julia",
    "section": "",
    "text": "As a baseline we need the average over sufficiently many years. We choose temperature data from the years 1971 to 2000 and calculate the mean temperature.\nFurther, we need the standard deviation of the long-term temperature data from 1901 to 2000.\nA smoothed data set based on a running mean is generated with an averaging window of 30 years length.\n\ndf_baseline = filter(row -&gt; (row.Jahr &gt; 1970) & (row.Jahr &lt; 2001), df)\nwhere = \"Deutschland\"\ncol = df_baseline[!, where];\nmw = mean(col)\n\ndf_longterm = filter(row -&gt; (row.Jahr &gt; 1900) & (row.Jahr &lt; 2001), df)\ncol = df_longterm[!, where];\nsd = std(col)\n\ndata = df[!, where] .- mw;\nm_data = runmean(data, 30);"
  },
  {
    "objectID": "posts/warming_stripes/Warming_Stripes_Makie.html#visualization",
    "href": "posts/warming_stripes/Warming_Stripes_Makie.html#visualization",
    "title": "Tutorial: How to generate your own warming stripes using Julia",
    "section": "",
    "text": "In the following code cell, we use Makie to generate a bar chart with annual temperature data relative to the baseline average of 1971 to 2000. The colormap is scaled to +/- 2.6 times the standard deviation of the long-term data from 1901 to 2000 (see How have these graphics been made? in the FAQ at showyourstripes.info).\nWe add as white line the smoothed temperature obtained by calculating running averages with a time window of 30 years length.\nThere is no doubt that the average temperature relative to the baseline data is approaching far more than 1.5 K (or 1.5 °C as it is commonly communicated) for the recent two decades since year 2000.\n\nset_theme!(theme_black())\nfig = Figure(resolution = (1200, 720), fontsize=24, fonts = (; regular= \"sans\"))\nax = Axis(fig[1, 1], \n    title = \"Temperature change in Germany relative to average of 1970-2001\",\n    ylabel = \"K\",\n    xautolimitmargin = (0.02,0.02),\n    yautolimitmargin = (0.02,0.02))\nbarplot!(ax, df.Jahr, data; width=1, gap=0, \n    strokewidth = 0.5, strokecolor = data,\n    color = data, \n    colorrange = (-2.6 * sd, +2.6 * sd),\n    colormap = wstripesmap)\nlines!(ax, df.Jahr, m_data, color=:white)\ntext!(\"Data source: http://opendata.dwd.de\\n\" * \n    \"https://showyourstripes.info by Ed Hawkins, University of Reading, UK\", \n    textsize=10,\n    align=(:left, :center),\n    position = (1880, -1.84))\ntext!(\"The white curve indicates a running average\\n\" *\n    \"with a window length of 30 years.\",\n    textsize = 10,\n    align=(:left, :center),\n    position=(1990, -1.84))\nfig\n\n\n\n\nThe next cell generates the well-known warming stripes for Germany.\n\nset_theme!(theme_minimal())\nfig = Figure(resolution = (780, 120))\nax = Axis(fig[1, 1],\nbackgroundcolor = :transparent,\n        leftspinevisible = false,\n        rightspinevisible = false,\n        bottomspinevisible = false,\n        topspinevisible = false,\n        xticklabelsvisible = false, \n        yticklabelsvisible = false,\n        xgridcolor = :transparent,\n        ygridcolor = :transparent,\n        xminorticksvisible = false,\n        yminorticksvisible = false,\n        xticksvisible = false,\n        yticksvisible = false,\n        xautolimitmargin = (0.0,0.0),\n        yautolimitmargin = (0.0,0.0),)\nhidedecorations!(ax)\nax.titlevisible=false\nhmap = heatmap!(df.Jahr, ones(size(df.Jahr)), data;\n    colorrange = (-2.6 * sd, +2.6 * sd), \n    colormap = wstripesmap)\nfig"
  },
  {
    "objectID": "posts/Bayes/index.html",
    "href": "posts/Bayes/index.html",
    "title": "What is Bayesian inference",
    "section": "",
    "text": "What is Bayesian inference?\nBayesian inference is a mathematical method for estimating the values of unknown parameters based on observed data and prior knowledge or beliefs about the parameters. It is a type of statistical inference that is based on Bayes’ theorem, which is a fundamental result in probability theory.\nThe basic idea of Bayesian inference is to use Bayes’ theorem to update our beliefs or knowledge about the values of the unknown parameters based on the observed data. This is done by expressing our prior beliefs about the parameters as a probability distribution, known as the prior distribution. Then, we use Bayes’ theorem to calculate the posterior distribution, which represents our updated beliefs about the parameters based on the observed data.\nBayesian inference has many advantages over other methods of statistical inference. It allows us to incorporate prior knowledge or beliefs about the parameters into our analysis, which can improve the accuracy of our estimates. It also allows us to easily incorporate uncertainty and incorporate new data as it becomes available. Additionally, Bayesian inference provides a natural framework for modeling complex systems, where the relationships between the variables are often unknown or uncertain.\nOverall, Bayesian inference is a powerful and flexible method for estimating the values of unknown parameters based on observed data and prior knowledge. It is widely used in many fields, including statistics, machine learning, and engineering, and it has many applications in data analysis and decision making.\nHere is an example of Julia code that uses the Turing.jl package to perform Bayesian inference on a simple model. This code uses the Monte Carlo Markov Chain (MCMC) sampling method to estimate the values of the unknown parameters.\n\nusing Turing\n\n# Define the model\n@model begin\n  # Define the unknown parameters\n  x ~ Normal(0, 1)\n  y ~ Normal(0, 1)\n\n  # Define the data\n  z = x + y\nend\n\n# Sample from the posterior distribution using MCMC\nsamples = sample(model, MCMC(), 1000)\n\n# Print the estimated values of x and y\nprintln(\"Estimated value of x: \", mean(samples[:x]))\nprintln(\"Estimated value of y: \", mean(samples[:y]))\n\nIn this code, the @model block defines the model that we want to fit to the data. It specifies that the unknown parameters x and y are normally distributed with mean 0 and standard deviation 1. The z variable is defined as the sum of x and y, which represents the observed data.\nNext, the sample() function is used to sample from the posterior distribution of the model using MCMC. This generates a set of samples that approximate the posterior distribution, and the mean() function is used to estimate the mean values of x and y from the samples.\nThis simple example shows how to use the Turing.jl package to perform Bayesian inference on a model with unknown parameters. The same approach can be used for more complex models and data, and the Turing.jl package provides many advanced features for modeling and inference.\n\n\n\n\n\n\nNote\n\n\n\nThis text has entirely been created by ChatGPT, a Large Language Model developed by openai.com.\nTry it out at chat.openai.com."
  },
  {
    "objectID": "posts/CO₂/index.html",
    "href": "posts/CO₂/index.html",
    "title": "2022 annual emission of CO₂",
    "section": "",
    "text": "According to the World Economic Forum, global CO₂ emissions from fossil fuels hits a record high in 2022 (link).\nThe fossil fuel based emissions in 2022 are estimated to remain at a high level of about 36.6 Gt/a.\nTo put the numbers into perspective, David Ho has proposed a time machine which takes us back a certain amount of time relativ to the annual CO₂ emission.\nWhat is CCS (Carbon Capture and Storage) able to contribute?\nThe Global CCS Institute reports a 44% increase of all CCS facilities under development with a projected total of 244 Mt/a. However, only 30 facilities were in operation and were able to capture 42.58 Mt/a.\nUsing David’s time machine idea, this is equivalent to about 10 hours of the annual CO₂ emission.\nIf all projected facilities were in operation, these 244 Mt/a would equal 2.4 days of annual emissions."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n2\n\n\n\\(\\alpha\\) math rendering works quite well."
  },
  {
    "objectID": "posts/coordinates/index.html",
    "href": "posts/coordinates/index.html",
    "title": "Geodetic coordinate transforms with Julia",
    "section": "",
    "text": "This blog post is about geodetic coordinate transforms using the Julia programming language.\nIn applied geophysics, the following question comes up frequently:\n\n\n\n\n\n\nProblem 💻\n\n\n\nHow can I transform geographical coordinates given as “latitude, longitude” into some other coordinate system, e.g., UTM?\n\n\nThe Julia package Proj.jl offers all functionality that is required.\nAfter installing the package using Julia’s package manager from the REPL, we are ready to go:\n\nusing Proj\nusing DataFrames, CSV\n\nLet’s assume that we have downloaded a set of coordinates from a handheld GPS receiver. The content of the data file coords.dat may look like this:\n# lat, lon\n50.924833, 13.330562\n50.982648, 13.530406\nWe first read in the data:\n\ndf = DataFrame(CSV.File(\"coords.dat\", delim=\",\"))\n\n2 rows × 2 columns\n\n\n\n\n# lat\nlon\n\n\n\nFloat64\nFloat64\n\n\n\n\n1\n50.9248\n13.3306\n\n\n2\n50.9826\n13.5304\n\n\n\n\n\n\nNext we arrange the data such that it is suitable for processing with Proj.jl:\n\nlatlon = Array(df)\n\n2×2 Matrix{Float64}:\n 50.9248  13.3306\n 50.9826  13.5304\n\n\nThe following step is essential. Since we transform data from one coordinate system into another, we have to inform Proj.jl about the source and target systems. To this end, we exploit the convenient EPSG codes.\n\ntrans = Proj.Transformation(\"EPSG:4326\", \"EPSG:25833\")\n\nTransformation\n    source: WGS 84\n    target: ETRS89 / UTM zone 33N\n    direction: forward\n\n\nThe next lines will finally transform our GPS coordinates into UTM zone 33 coordinates which we refer to as easting and northing:\n\netrs = [trans(latlon[i, :]) for i in 1:size(latlon, 1)]\nUTM = hcat(collect.(etrs)...);\n\neasting = UTM[1, :]\nnorthing = UTM[2, :]\n@show easting\n@show northing;\n\neasting = [382670.42457542894, 396843.0546304857]\nnorthing = [5.642793241297958e6, 5.648923257065746e6]"
  },
  {
    "objectID": "posts/Paths/index.html",
    "href": "posts/Paths/index.html",
    "title": "Mac OS: System-wide PATHs for GUI apps",
    "section": "",
    "text": "Problem: GUI applications often don’t find an app when its directory is already in the PATH environnment variable.\nIn my case, I was unable to start jupyter from inside Quarto.\nFor recent Mac OS releases, the solution to the problem is easy:\nEdit /etc/paths and add the needed paths. Restart your Finder. That’s it."
  },
  {
    "objectID": "posts/Paths/index.html#set-system-wide-path-for-mac-os-gui-applications",
    "href": "posts/Paths/index.html#set-system-wide-path-for-mac-os-gui-applications",
    "title": "Mac OS: System-wide PATHs for GUI apps",
    "section": "",
    "text": "Problem: GUI applications often don’t find an app when its directory is already in the PATH environnment variable.\nIn my case, I was unable to start jupyter from inside Quarto.\nFor recent Mac OS releases, the solution to the problem is easy:\nEdit /etc/paths and add the needed paths. Restart your Finder. That’s it."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome to my Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog.\n\n\nRecently, I discovered Quarto, which offers a functionality that I was missing in other tools.\n\n\n\n\nFirst and foremost, using Quarto one can easily deploy a website, a blog post, a presentation, a static html page, or you name it.\nThis blog is a Quarto project which I edit in RStudio.\nIts sources are hosted at GitHub and deployed as a static site using GitHub Pages."
  },
  {
    "objectID": "posts/welcome/index.html#why-quarto",
    "href": "posts/welcome/index.html#why-quarto",
    "title": "Welcome to my Blog",
    "section": "",
    "text": "Recently, I discovered Quarto, which offers a functionality that I was missing in other tools."
  },
  {
    "objectID": "posts/welcome/index.html#what-is-quarto",
    "href": "posts/welcome/index.html#what-is-quarto",
    "title": "Welcome to my Blog",
    "section": "",
    "text": "First and foremost, using Quarto one can easily deploy a website, a blog post, a presentation, a static html page, or you name it.\nThis blog is a Quarto project which I edit in RStudio.\nIts sources are hosted at GitHub and deployed as a static site using GitHub Pages."
  },
  {
    "objectID": "posts/Julia-and-Quarto/index.html",
    "href": "posts/Julia-and-Quarto/index.html",
    "title": "Quarto and Julia",
    "section": "",
    "text": "Why mix Julia and Quarto?\nThere are quite a few development environments available for Julia, e.g., Visual Studio Code, Jupyter, Pluto.jl.\nAll of the above can be used to develop code or implement and test ideas. The main difference is the intended workflow.\nFor the purpose of teaching, until now I prefer Pluto.jl notebooks.\nHowever, even though exporting the final Pluto Notebook is possible without problems, the design of the exported HTML or PDF page cannot be altered. Further, there is no straightforward way to easily deploy a slide show presentation directly out of your notebook.\nThere exist, however, literate programming tools that are able to generate, e.g., a tutorial or a documentation by parsing comments in the Julia source files — see, e.g.,\n\nDocumenter.jl\nLiterate.jl\nFranklin.jl\nPublish.jl\nWeave.jl.\n\nFurther, Jupyter notebooks are web-based interactive computational environments for creating notebook documents. It contains an ordered list of input and output cells which can contain code, Markdown text, plots, and equations."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my blog",
    "section": "",
    "text": "Mac OS: System-wide PATHs for GUI apps\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nmac\n\n\n\n\n\n\n\n\n\nNov 9, 2023\n\n\nRalph-Uwe Börner\n\n\n\n\n\n\n\n\n\n\n\n\n2022 annual emission of CO₂\n\n\n\n\n\n\nscience\n\n\n\n\n\n\n\n\n\nJan 12, 2023\n\n\nRalph-Uwe Börner\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial: How to generate your own warming stripes using Julia\n\n\n\n\n\n\ncode\n\n\njulia\n\n\nclimate\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Bayesian inference\n\n\n\n\n\n\nscience\n\n\nchatgpt\n\n\n\n\n\n\n\n\n\nDec 2, 2022\n\n\nRalph-Uwe Börner\n\n\n\n\n\n\n\n\n\n\n\n\nGeophysical inversion\n\n\n\n\n\n\ncode\n\n\npython\n\n\ngeophysics\n\n\n\n\n\n\n\n\n\nNov 24, 2022\n\n\nRalph-Uwe Börner\n\n\n\n\n\n\n\n\n\n\n\n\nGeodetic coordinate transforms with Julia\n\n\n\n\n\n\ncode\n\n\njulia\n\n\n\n\n\n\n\n\n\nOct 26, 2022\n\n\nRalph-Uwe Börner\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\njulia\n\n\n\n\n\n\n\n\n\nSep 30, 2022\n\n\nRalph-Uwe Börner\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to my Blog\n\n\n\n\n\n\nquarto\n\n\n\n\n\n\n\n\n\nSep 30, 2022\n\n\nRalph-Uwe Börner\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto and Julia\n\n\n\n\n\n\ncode\n\n\njulia\n\n\n\n\n\n\n\n\n\nSep 30, 2022\n\n\nRalph-Uwe Börner\n\n\n\n\n\n\n\n\n\n\n\n\nJupyter example\n\n\n\n\n\n\ncode\n\n\njupyter\n\n\nquarto\n\n\n\n\n\n\n\n\n\nSep 29, 2022\n\n\nRalph-Uwe Börner\n\n\n\n\n\n\nNo matching items"
  }
]